{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5499848d",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5cbabd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy  : 1.24.4\n",
      "sklearn: 1.0.2\n",
      "pandas : 1.4.1\n",
      "\n",
      "ipywidgets: 7.7.1\n",
      "cv2       : 4.8.1\n",
      "PIL       : 9.0.1\n",
      "matplotlib: 3.5.1\n",
      "plotly    : 5.18.0\n",
      "netron    : not installed\n",
      "\n",
      "torch      : 1.12.0.dev20220327+cu113\n",
      "torchvision: 0.13.0.dev20220327+cu113\n",
      "torchaudio : 0.12.0.dev20220327+cu113\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%reload_ext watermark\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%watermark -p numpy,sklearn,pandas\n",
    "%watermark -p ipywidgets,cv2,PIL,matplotlib,plotly,netron\n",
    "%watermark -p torch,torchvision,torchaudio\n",
    "# %watermark -p tensorflow,tensorboard,tflite\n",
    "# %watermark -p onnx,tf2onnx,onnxruntime,tensorrt,tvm\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format='retina'\n",
    "# %config IPCompleter.use_jedi = False\n",
    "\n",
    "# %matplotlib inline\n",
    "# %matplotlib widget\n",
    "# from IPython.display import display, Markdown, HTML, IFrame, Image, Javascript\n",
    "# from IPython.core.magic import register_line_cell_magic, register_line_magic, register_cell_magic\n",
    "# display(HTML('<style>.container { width:%d%% !important; }</style>' % 90))\n",
    "\n",
    "import sys, os, io, logging, time, random, math\n",
    "import json, base64, requests, shutil\n",
    "import argparse, shlex, signal\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from glob import glob\n",
    "import re\n",
    "import yaml\n",
    "\n",
    "np.set_printoptions(\n",
    "    edgeitems=3, infstr='inf',\n",
    "    linewidth=75, nanstr='nan', precision=6,\n",
    "    suppress=True, threshold=100, formatter=None)\n",
    "\n",
    "argparse.ArgumentParser.exit = lambda *arg, **kwargs: _IGNORE_\n",
    "\n",
    "def _IMPORT(x, tag='main', debug=False):\n",
    "    def __request_text(url):\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            return response.text\n",
    "        else:\n",
    "            raise RuntimeError(url)\n",
    "    try:\n",
    "        x = x.strip()\n",
    "        if x[0] == '/' or x[1] == '/':\n",
    "            with open(x) as fr:\n",
    "                x = fr.read()\n",
    "        elif 'github' in x or 'gitee' in x:\n",
    "            if x.startswith('import '):\n",
    "                x = x[7:]\n",
    "            if x.startswith('https://'):\n",
    "                x = x[8:]\n",
    "            if not x.endswith('.py'):\n",
    "                x = x + '.py'\n",
    "            x = x.replace('blob/main/', '').replace('blob/master/', '')\n",
    "            if x.startswith('raw.githubusercontent.com'):\n",
    "                x = 'https://' + x\n",
    "                x = __request_text(x)\n",
    "            elif x.startswith('github.com'):\n",
    "                x = x.replace('github.com', 'raw.githubusercontent.com')\n",
    "                mod = x.split('/')\n",
    "                x = 'https://' + '/'.join(mod[:3]) + f'/{tag}/' + '/'.join(mod[-3:])\n",
    "                x = __request_text(x)\n",
    "            elif x.startswith('gitee.com'):\n",
    "                mod = x.split('/')\n",
    "                x = 'https://' + '/'.join(mod[:3]) + f'/raw/{tag}/' + '/'.join(mod[3:])\n",
    "                x = __request_text(x)\n",
    "        if debug:\n",
    "            return x\n",
    "        else:\n",
    "            exec(x, globals())\n",
    "    except Exception as err:\n",
    "        # sys.stderr.write(f'request {x} : {err}')\n",
    "       pass\n",
    "\n",
    "def _DIR(x, dumps=True, ret=True):\n",
    "    attrs = sorted([y for y in dir(x) if not y.startswith('_')])\n",
    "    result = '%s: %s' % (str(type(x))[8:-2], json.dumps(attrs) if dumps else attrs)\n",
    "    if ret:\n",
    "        return result\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bfeb7be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  set_rng_seed(x):\n",
    "    try:\n",
    "        random.seed(x)\n",
    "        np.random.seed(x)\n",
    "        torch.manual_seed(x)\n",
    "    except: \n",
    "        pass\n",
    "    \n",
    "import yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ed324",
   "metadata": {},
   "source": [
    "## Global "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f62540b",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_DIR = '/jupyter/hzcsbet/gamebet'\n",
    "DATASET_DIR = f'{TOP_DIR}/datasets/SoccerNet/tracking'\n",
    "CHECKPOINTS_DIR = f'{TOP_DIR}/checkpoints'\n",
    "\n",
    "labels = ['ball', 'player', 'referee', 'goalkeepers']\n",
    "label_dict = {'ball': 0, 'player': 1, 'referee': 2, 'goalkeeper': 3, 'goalkeepers': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97f513bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Open the video file\u001b[39;00m\n\u001b[1;32m     11\u001b[0m video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTOP_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/datasets/0bfacc_5.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 12\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvideo_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msave\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ultralytics/engine/model.py:250\u001b[0m, in \u001b[0;36mModel.predict\u001b[0;34m(self, source, stream, predictor, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor \u001b[38;5;241m=\u001b[39m (predictor \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_smart_load(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredictor\u001b[39m\u001b[38;5;124m'\u001b[39m))(overrides\u001b[38;5;241m=\u001b[39margs, _callbacks\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallbacks)\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredictor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_cli\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# only update args if predictor is already setup\u001b[39;00m\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m get_cfg(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredictor\u001b[38;5;241m.\u001b[39margs, args)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ultralytics/engine/predictor.py:320\u001b[0m, in \u001b[0;36mBasePredictor.setup_model\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msetup_model\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;124;03m\"\"\"Initialize YOLO model with given parameters and set it to evaluation mode.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 320\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel \u001b[38;5;241m=\u001b[39m \u001b[43mAutoBackend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselect_device\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    322\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdnn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdnn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfp16\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhalf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    325\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mfuse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    328\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mdevice  \u001b[38;5;66;03m# update device\u001b[39;00m\n\u001b[1;32m    329\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mhalf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mfp16  \u001b[38;5;66;03m# update half\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ultralytics/nn/autobackend.py:122\u001b[0m, in \u001b[0;36mAutoBackend.__init__\u001b[0;34m(self, weights, device, dnn, data, fp16, fuse, verbose)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;66;03m# Load model\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m nn_module:  \u001b[38;5;66;03m# in-memory PyTorch model\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mweights\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    123\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfuse(verbose\u001b[38;5;241m=\u001b[39mverbose) \u001b[38;5;28;01mif\u001b[39;00m fuse \u001b[38;5;28;01melse\u001b[39;00m model\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkpt_shape\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:907\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    903\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m    905\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m--> 907\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/ultralytics/nn/tasks.py:183\u001b[0m, in \u001b[0;36mBaseModel._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    174\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    175\u001b[0m \u001b[38;5;124;03m    Applies a function to all the tensors in the model that are not parameters or registered buffers.\u001b[39;00m\n\u001b[1;32m    176\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;124;03m        (BaseModel): An updated BaseModel object.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 183\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# Detect()\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(m, (Detect, Segment)):\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:905\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    904\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m--> 905\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the YOLOv8 model\n",
    "# model = YOLO('yolov8n.pt')          ### Pre-trained weights\n",
    "\n",
    "model = YOLO('runs/detect/train4/weights/best.pt')          ### weights from trained model\n",
    "\n",
    "images = []\n",
    "# Open the video file\n",
    "video_path = f\"{TOP_DIR}/datasets/0bfacc_5.mp4\"\n",
    "model.predict(source=video_path, save=True)\n",
    "\n",
    "# cap = cv2.VideoCapture(video_path)\n",
    "# \n",
    "# # Loop through the video frames\n",
    "# while cap.isOpened():\n",
    "#     # Read a frame from the video\n",
    "#     success, frame = cap.read()\n",
    "# \n",
    "#     if success:\n",
    "#         # Run YOLOv8 tracking on the frame, persisting tracks between frames\n",
    "#         # results = model.track(frame, persist=True, show=True, tracker=\"bytetrack.yaml\")\n",
    "#         results = model.predict(\n",
    "#             source=frame,\n",
    "#             mode=\"predict\",\n",
    "#             save=False,\n",
    "#             # device=\"cpu\"\n",
    "#         )\n",
    "#         print(dir(results))\n",
    "#         break\n",
    "#         # Visualize the results on the frame\n",
    "#         # annotated_frame = results[0].plot()\n",
    "# \n",
    "#         # Display the annotated frame\n",
    "#         # cv2.imshow(\"YOLOv8 Tracking\", annotated_frame)\n",
    "#         # images.append(annotated_frame)\n",
    "# \n",
    "#     else:\n",
    "#         # Break the loop if the end of the video is reached\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222b31df",
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84f4f72",
   "metadata": {},
   "source": [
    "## Data Format Convert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3598c5aa",
   "metadata": {},
   "source": [
    "### Data Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "751241e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "yolo_base = f'{TOP_DIR}/datasets/yolov8'\n",
    "\n",
    "#(1) image file path\n",
    "yolo_train_img_dir = f'{yolo_base}/images/train'\n",
    "yolo_valid_img_dir = f'{yolo_base}/images/valid'\n",
    "\n",
    "#(2) label file path\n",
    "yolo_train_label_dir = f'{yolo_base}/labels/train'\n",
    "yolo_valid_label_dir = f'{yolo_base}/labels/valid'\n",
    "\n",
    "#(3) config file path\n",
    "yaml_file = f'{yolo_base}/data.yaml'\n",
    "\n",
    "os.makedirs(yolo_train_img_dir, exist_ok=True)\n",
    "os.makedirs(yolo_valid_img_dir, exist_ok=True)\n",
    "os.makedirs(yolo_train_label_dir, exist_ok=True)\n",
    "os.makedirs(yolo_valid_label_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "93001e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/jupyter/hzcsbet/gamebet/datasets/SoccerNet/tracking/test/SNMOT-116\n",
      "det  gameinfo.ini  gt  img1  seqinfo.ini\n"
     ]
    }
   ],
   "source": [
    "snmot_dirs = {}\n",
    "snmot_dirs['test'] = sorted(glob(f'{DATASET_DIR}/test/SNMOT*'))\n",
    "snmot_dirs['train'] = sorted(glob(f'{DATASET_DIR}/train/SNMOT*'))\n",
    "t1 = snmot_dirs['test'][0]\n",
    "print(t1)\n",
    "!ls $t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6604a94b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequence]\r\n",
      "name=SNMOT-116\r\n",
      "imDir=img1\r\n",
      "frameRate=25\r\n",
      "seqLength=750\r\n",
      "imWidth=1920\r\n",
      "imHeight=1080\r\n",
      "imExt=.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!cat $t1/seqinfo.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e54ae0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequence]\r\n",
      "name=SNMOT-116\r\n",
      "gameID=7\r\n",
      "actionPosition=975293\r\n",
      "actionClass=Corner\r\n",
      "visibility=visible\r\n",
      "clipStart=969000\r\n",
      "gameTimeStart=1 - 16:09\r\n",
      "clipStop=999000\r\n",
      "gameTimeStop=1 - 16:39\r\n",
      "num_tracklets=27\r\n",
      "trackletID_1= player team left;4\r\n",
      "trackletID_2= player team left;93\r\n",
      "trackletID_3= player team right;25\r\n",
      "trackletID_4= referee;main\r\n",
      "trackletID_5= player team left;A\r\n",
      "trackletID_6= player team left;11\r\n",
      "trackletID_7= player team right;34\r\n",
      "trackletID_8= player team left;44\r\n",
      "trackletID_9= player team right;33\r\n",
      "trackletID_10= player team right;20\r\n",
      "trackletID_11= player team right;10\r\n",
      "trackletID_12= player team right;31\r\n",
      "trackletID_13= player team right;14\r\n",
      "trackletID_14= player team left;33\r\n",
      "trackletID_15= player team left;8\r\n",
      "trackletID_16= player team right;36\r\n",
      "trackletID_17= player team left;36\r\n",
      "trackletID_18= player team right;8\r\n",
      "trackletID_19= goalkeepers team left;1\r\n",
      "trackletID_20= ball;1\r\n",
      "trackletID_21= player team right;B\r\n",
      "trackletID_22= player team right;E\r\n",
      "trackletID_23= player team left;C\r\n",
      "trackletID_24= player team left;X\r\n",
      "trackletID_25= referee;side bottom\r\n",
      "trackletID_26= player team left;D\r\n",
      "trackletID_27= player team right;9\r\n"
     ]
    }
   ],
   "source": [
    "!cat $t1/gameinfo.ini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dddd3e7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1,1,136,520,51,135,1,-1,-1,-1\r\n",
      "2,1,138,521,50,134,1,-1,-1,-1\r\n",
      "3,1,140,521,48,133,1,-1,-1,-1\r\n",
      "4,1,142,521,47,132,1,-1,-1,-1\r\n",
      "5,1,143,522,46,131,1,-1,-1,-1\r\n",
      "6,1,146,523,44,129,1,-1,-1,-1\r\n",
      "7,1,146,522,45,129,1,-1,-1,-1\r\n",
      "8,1,147,522,45,130,1,-1,-1,-1\r\n",
      "9,1,148,521,46,130,1,-1,-1,-1\r\n",
      "10,1,149,521,47,131,1,-1,-1,-1\r\n"
     ]
    }
   ],
   "source": [
    "!head -n 10 $t1/gt/gt.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39bf192e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741,27,148,396,48,113,1,-1,-1,-1\r\n",
      "742,27,140,397,49,112,1,-1,-1,-1\r\n",
      "743,27,130,399,51,112,1,-1,-1,-1\r\n",
      "744,27,125,400,50,112,1,-1,-1,-1\r\n",
      "745,27,118,401,48,113,1,-1,-1,-1\r\n",
      "746,27,110,403,46,113,1,-1,-1,-1\r\n",
      "747,27,103,404,44,113,1,-1,-1,-1\r\n",
      "748,27,94,405,42,114,1,-1,-1,-1\r\n",
      "749,27,89,406,42,114,1,-1,-1,-1\r\n",
      "750,27,80,409,42,114,1,-1,-1,-1\r\n"
     ]
    }
   ],
   "source": [
    "!tail -n 10 $t1/gt/gt.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a8c2c496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequence]\r\n",
      "name=SNMOT-116\r\n",
      "imDir=img1\r\n",
      "frameRate=25\r\n",
      "seqLength=750\r\n",
      "imWidth=1920\r\n",
      "imHeight=1080\r\n",
      "imExt=.jpg\r\n"
     ]
    }
   ],
   "source": [
    "!cat $t1/seqinfo.ini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04e3372c",
   "metadata": {},
   "source": [
    "### Parse Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "66d7a56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from x,y,w,h to yolo format\n",
    "def get_yolo_format_bbox(img_w, img_h, box):\n",
    "    w = int(box[2])\n",
    "    h = int(box[3])\n",
    "    xc = int(box[0]) + int(np.round(w/2))\n",
    "    yc = int(box[1]) + int(np.round(h/2))\n",
    "    box = [xc/img_w, yc/img_h, w/img_w, h/img_h]\n",
    "    box = [f\"{i:.4g}\" for i in box]\n",
    "    return box\n",
    "    \n",
    "# get SoccerNet label info \n",
    "def get_game_info(info):\n",
    "    results = {}\n",
    "    for line in open(info):\n",
    "        m = re.match('trackletID_(\\d+)= (\\S*).*', line.replace(';', ' '))\n",
    "        if m:\n",
    "            if m.group(2) not in label_dict:\n",
    "                continue \n",
    "            results[m.group(1)] = m.group(2)\n",
    "    return results\n",
    "\n",
    "def get_seq_info(info):\n",
    "    results = {}\n",
    "    for line in open(info):\n",
    "        if line.startswith('name'):\n",
    "            results['name'] = line.split('=')[1].strip()\n",
    "        elif line.startswith('imDir'):\n",
    "            results['img_dir'] = line.split('=')[1].strip()\n",
    "        elif line.startswith('imWidth'):\n",
    "            results['img_w'] = int(line.split('=')[1].strip())\n",
    "        elif line.startswith('imHeight'):\n",
    "            results['img_h'] = int(line.split('=')[1].strip())\n",
    "        elif line.startswith('imExt'):\n",
    "            results['img_ext'] = line.split('=')[1].strip()\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d091a16",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SNMOT-116',\n",
       " 'img_dir': 'img1',\n",
       " 'img_w': 1920,\n",
       " 'img_h': 1080,\n",
       " 'img_ext': '.jpg'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_info = get_seq_info(f'{t1}/seqinfo.ini')\n",
    "seq_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebd4c054",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1': 'player',\n",
       " '2': 'player',\n",
       " '3': 'player',\n",
       " '4': 'referee',\n",
       " '5': 'player',\n",
       " '6': 'player',\n",
       " '7': 'player',\n",
       " '8': 'player',\n",
       " '9': 'player',\n",
       " '10': 'player',\n",
       " '11': 'player',\n",
       " '12': 'player',\n",
       " '13': 'player',\n",
       " '14': 'player',\n",
       " '15': 'player',\n",
       " '16': 'player',\n",
       " '17': 'player',\n",
       " '18': 'player',\n",
       " '19': 'goalkeepers',\n",
       " '20': 'ball',\n",
       " '21': 'player',\n",
       " '22': 'player',\n",
       " '23': 'player',\n",
       " '24': 'player',\n",
       " '25': 'referee',\n",
       " '26': 'player',\n",
       " '27': 'player'}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_info = get_game_info(f'{t1}/gameinfo.ini')\n",
    "game_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91b797b",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for phase, dirs in snmot_dirs.items():\n",
    "    if len(dirs) == 0:\n",
    "        continue\n",
    "    for mot in dirs:\n",
    "        seq_info = get_seq_info(f'{mot}/seqinfo.ini')\n",
    "        game_info = get_game_info(f'{mot}/gameinfo.ini')\n",
    "        result = {}\n",
    "        for line in open(f'{mot}/gt/gt.txt'):\n",
    "            imgid, labid, *box = line.split(',')[:6]\n",
    "            if labid in game_info:\n",
    "                imgid = f'{int(imgid):06}'\n",
    "                if imgid not in result:\n",
    "                    result[imgid] = []\n",
    "                box = get_yolo_format_bbox(seq_info['img_w'], seq_info['img_h'], box)\n",
    "                result[imgid].append([label_dict[game_info[labid]], *box])\n",
    "        seq_info['data'] = result\n",
    "        seq_info['phase'] = phase\n",
    "        results.append(seq_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bcf4b5",
   "metadata": {},
   "source": [
    "### Train and Valid Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401b2e28",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "set_rng_seed(888)\n",
    "for item in results:\n",
    "    for imgid, data in item['data'].items():\n",
    "        img_dst_file = f'{item[\"name\"]}_{imgid}{item[\"img_ext\"]}'\n",
    "        lab_dst_file = f'{item[\"name\"]}_{imgid}.txt'\n",
    "        img_src_path = f'{DATASET_DIR}/{item[\"phase\"]}/{item[\"name\"]}/{item[\"img_dir\"]}/{imgid}{item[\"img_ext\"]}'\n",
    "        if not os.path.exists(img_src_path):\n",
    "            print('Not found: ', img_src_path)\n",
    "            continue\n",
    "        if np.random.random(1) > 0.9:\n",
    "            img_dst_path = f'{yolo_valid_img_dir}/{img_dst_file}'\n",
    "            lab_dst_path = f'{yolo_valid_label_dir}/{lab_dst_file}'\n",
    "        else:\n",
    "            img_dst_path = f'{yolo_train_img_dir}/{img_dst_file}'\n",
    "            lab_dst_path = f'{yolo_train_label_dir}/{lab_dst_file}'\n",
    "        if not os.path.exists(img_dst_path):\n",
    "            os.symlink(img_src_path, img_dst_path)\n",
    "        with open(lab_dst_path, 'w') as fw:\n",
    "            for line in data:\n",
    "                fw.write(f'%d %s %s %s %s\\n' % (line[0], line[1], line[2], line[3], line[4]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c37500",
   "metadata": {
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "data_yaml = dict(\n",
    "    train = yolo_train_img_dir,\n",
    "    val = yolo_valid_img_dir,\n",
    "    nc = 4,\n",
    "    names = labels\n",
    ")\n",
    "\n",
    "with open(yaml_file, 'w') as fw:\n",
    "    yaml.dump(data_yaml, fw, default_flow_style=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7031bafc",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb4b8b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2bbc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.229 ðŸš€ Python-3.8.10 torch-1.12.0.dev20220327+cu113 CUDA:0 (Tesla P40, 24452MiB)\n",
      "WARNING âš ï¸ Upgrade to torch>=2.0.0 for deterministic training.\n",
      "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=/jupyter/hzcsbet/gamebet/checkpoints/yolov8m.pt, data=/jupyter/hzcsbet/gamebet/datasets/yolov8/data.yaml, epochs=100, time=None, patience=50, batch=64, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train6, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train6\n",
      "Overriding model.yaml nc=80 with nc=4\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1      1392  ultralytics.nn.modules.conv.Conv             [3, 48, 3, 2]                 \n",
      "  1                  -1  1     41664  ultralytics.nn.modules.conv.Conv             [48, 96, 3, 2]                \n",
      "  2                  -1  2    111360  ultralytics.nn.modules.block.C2f             [96, 96, 2, True]             \n",
      "  3                  -1  1    166272  ultralytics.nn.modules.conv.Conv             [96, 192, 3, 2]               \n",
      "  4                  -1  4    813312  ultralytics.nn.modules.block.C2f             [192, 192, 4, True]           \n",
      "  5                  -1  1    664320  ultralytics.nn.modules.conv.Conv             [192, 384, 3, 2]              \n",
      "  6                  -1  4   3248640  ultralytics.nn.modules.block.C2f             [384, 384, 4, True]           \n",
      "  7                  -1  1   1991808  ultralytics.nn.modules.conv.Conv             [384, 576, 3, 2]              \n",
      "  8                  -1  2   3985920  ultralytics.nn.modules.block.C2f             [576, 576, 2, True]           \n",
      "  9                  -1  1    831168  ultralytics.nn.modules.block.SPPF            [576, 576, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  2   1993728  ultralytics.nn.modules.block.C2f             [960, 384, 2]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  2    517632  ultralytics.nn.modules.block.C2f             [576, 192, 2]                 \n",
      " 16                  -1  1    332160  ultralytics.nn.modules.conv.Conv             [192, 192, 3, 2]              \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  2   1846272  ultralytics.nn.modules.block.C2f             [576, 384, 2]                 \n",
      " 19                  -1  1   1327872  ultralytics.nn.modules.conv.Conv             [384, 384, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  2   4207104  ultralytics.nn.modules.block.C2f             [960, 576, 2]                 \n",
      " 22        [15, 18, 21]  1   3778012  ultralytics.nn.modules.head.Detect           [4, [192, 384, 576]]          \n",
      "Model summary: 295 layers, 25858636 parameters, 25858620 gradients, 79.1 GFLOPs\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transferred 469/475 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train6', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /data/hzcsai_com/hzcsbet/gamebet/datasets/yolov8/labels/train.cache... 33056 images, 0 backgrounds, 0 corrupt: 100% 33056/33056 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING âš ï¸ /data/hzcsai_com/hzcsbet/gamebet/datasets/yolov8/images/train/SNMOT-194_000585.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning /data/hzcsai_com/hzcsbet/gamebet/datasets/yolov8/labels/valid.cache... 3694 images, 0 backgrounds, 0 corrupt: 100% 3694/3694 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs/detect/train6/labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01, momentum=0.9) with parameter groups 77 weight(decay=0.0), 84 weight(decay=0.0005), 83 bias(decay=0.0)\n",
      "100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/517 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "      1/100      24.3G       1.33     0.8002     0.9358        793        640: 100% 517/517 [26:20<00:00,  3.06s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 29/29 [00:49<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3694      56328       0.85      0.745      0.778      0.472\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/517 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "      2/100      24.2G       1.26     0.6092     0.9111        972        640: 100% 517/517 [25:49<00:00,  3.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 29/29 [00:47<00:00,  1.63s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3694      56328      0.841       0.77      0.794      0.482\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/517 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "      3/100      24.2G      1.243     0.5989     0.9095        794        640: 100% 517/517 [25:49<00:00,  3.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 29/29 [00:47<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3694      56328      0.829      0.746      0.776      0.458\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/517 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "      4/100      24.5G       1.21     0.5755     0.9027        858        640: 100% 517/517 [25:49<00:00,  3.00s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 29/29 [00:47<00:00,  1.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3694      56328      0.851       0.76      0.796      0.494\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/517 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "      5/100      24.2G      1.158     0.5434     0.8925        716        640: 100% 517/517 [25:44<00:00,  2.99s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 29/29 [00:49<00:00,  1.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all       3694      56328      0.884       0.77      0.811      0.526\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% 0/517 [00:00<?, ?it/s]/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py:1383: UserWarning: positional arguments and argument \"destination\" are deprecated. nn.Module.state_dict will not accept them in the future. Refer to https://pytorch.org/docs/master/generated/torch.nn.Module.html#torch.nn.Module.state_dict for details.\n",
      "  warnings.warn(\n",
      "      6/100      24.2G       1.13     0.5277     0.8863       1699        640:  20% 102/517 [05:04<20:37,  2.98s/it]"
     ]
    }
   ],
   "source": [
    "model = YOLO(f'{CHECKPOINTS_DIR}/yolov8m.pt')\n",
    "results = model.train(data=yaml_file, epochs=100, batch=64, imgsz=640, save_dir=CHECKPOINTS_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e8b01c",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d8d3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785494e6",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d740fd88",
   "metadata": {},
   "source": [
    "- [BoT-SORT: Robust Associations Multi-Pedestrian Tracking][5]\n",
    "- [ByteTrack: Multi-Object Tracking by Associating Every Detection Box][1]\n",
    "- [SoccerNet - Tracking][2]\n",
    "- [Cool experiments at the intersection of Computer Vision and Sports][3]\n",
    "- [Football players tracking â€” identifying playersâ€™ team based on their jersey colors using OpenCV][4]\n",
    "- https://readmedium.com/chess-rolls-or-basketball-lets-create-a-custom-object-detection-model-ef53028eac7d\n",
    "- https://medium.com/@amirhossein477/how-to-obtain-the-birds-eye-view-of-a-soccer-game-regardless-of-camera-angle-changes-90d627acd522\n",
    "- https://medium.com/@amritangshu.mukherjee/tracking-football-players-with-yolov5-bytetrack-efa317c9aaa4\n",
    "- https://www.jlburkhead.com\n",
    "\n",
    "[5]: https://arxiv.org/pdf/2\n",
    "[4]: https://towardsdatascience.com/football-players-tracking-identifying-players-team-based-on-their-jersey-colors-using-opencv-7eed1b8a1095\n",
    "[3]: https://github.com/SkalskiP/sports\n",
    "[2]: https://github.com/SoccerNet/sn-tracking\n",
    "[1]: https://arxiv.org/pdf/2110.06864.pdf"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "168px",
    "left": "1499px",
    "top": "67.125px",
    "width": "362px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
